{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_model_selection.py",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegrattarola/ml-18-19/blob/master/04_model_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwPfDFnz1ECg",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U255cI3117T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data\n",
        "import pandas as pd\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "data = pd.read_csv(url, delimiter=';')\n",
        "\n",
        "# Extract features\n",
        "x = data[data.columns[:-1]].values\n",
        "\n",
        "# Normalize features\n",
        "x -= np.mean(x, axis=0)\n",
        "x /= np.std(x, axis=0)\n",
        "\n",
        "# Extact targets\n",
        "quality = data['quality'].values\n",
        "y = (quality >= 6).astype(int)\n",
        "\n",
        "# Split the data into training and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "x, x_test, y, y_test = train_test_split(x, y, test_size=0.1, stratify=y)\n",
        "\n",
        "print('Training set size: {}'.format(x.shape[0]))\n",
        "print('Test set size: {}'.format(x_test.shape[0]))\n",
        "\n",
        "print('\\nX train')\n",
        "print(x)\n",
        "\n",
        "print('\\nY train')\n",
        "plt.hist(y);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi1eBuTH7xhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup K-fold cross-validation\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "k = 10\n",
        "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
        "\n",
        "scores_lr = []\n",
        "for train_indices, val_indices in kf.split(x, y):\n",
        "    print('###################################################################')\n",
        "    print('Training set size:   {}'.format(train_indices.shape[0]))\n",
        "    print('Validation set size: {}'.format(val_indices.shape[0]))\n",
        "    \n",
        "    x_train = x[train_indices]\n",
        "    x_val = x[val_indices]\n",
        "    y_train = y[train_indices]\n",
        "    y_val = y[val_indices]\n",
        "    \n",
        "    model = LogisticRegression(solver='liblinear')  # Specify solver to disable warning\n",
        "    model.fit(x_train, y_train)\n",
        "    \n",
        "    score = model.score(x_val, y_val)\n",
        "    scores_lr.append(score)\n",
        "    print('Accuracy: {}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04_OJGxy8PUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate estimated performance\n",
        "acc_mean = np.mean(scores_lr)\n",
        "acc_std = np.std(scores_lr)\n",
        "print('Expected accuracy: {:.2f} +- {:.2f}'.format(acc_mean, acc_std))\n",
        "\n",
        "# Evaluate actual performance\n",
        "model = LogisticRegression(solver='liblinear')  # Specify solver to disable warning\n",
        "model.fit(x, y)\n",
        "score = model.score(x_test, y_test)\n",
        "print('Actual accuracy:   {:.3f}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CV2-gUX1ObG",
        "colab_type": "text"
      },
      "source": [
        "## Classification and regression trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkL_i2ab12lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "k = 10\n",
        "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
        "\n",
        "scores_dt = []\n",
        "for train_indices, val_indices in kf.split(x, y):\n",
        "    print('###################################################################')\n",
        "    print('Training set size:   {}'.format(train_indices.shape[0]))\n",
        "    print('Validation set size: {}'.format(val_indices.shape[0]))\n",
        "    \n",
        "    x_train = x[train_indices]\n",
        "    x_val = x[val_indices]\n",
        "    y_train = y[train_indices]\n",
        "    y_val = y[val_indices]\n",
        "    \n",
        "    model = DecisionTreeClassifier()\n",
        "    model.fit(x_train, y_train)\n",
        "    \n",
        "    score = model.score(x_val, y_val)\n",
        "    scores_dt.append(score)\n",
        "    print('Accuracy: {}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYYVCVcwDuwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate estimated performance\n",
        "acc_mean = np.mean(scores_dt)\n",
        "acc_std = np.std(scores_dt)\n",
        "print('Expected accuracy: {:.2f} +- {:.2f}'.format(acc_mean, acc_std))\n",
        "\n",
        "# Evaluate actual performance\n",
        "model = DecisionTreeClassifier()  # Specify solver to disable warning\n",
        "model.fit(x, y)\n",
        "score = model.score(x_test, y_test)\n",
        "print('Actual accuracy:   {:.3f}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeefhNmE1UBo",
        "colab_type": "text"
      },
      "source": [
        "## Random forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSDmN_sj1220",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "k = 10\n",
        "kf = StratifiedKFold(n_splits=k, shuffle=True)\n",
        "\n",
        "scores_rf = []\n",
        "for train_indices, val_indices in kf.split(x, y):\n",
        "    print('###################################################################')\n",
        "    print('Training set size:   {}'.format(train_indices.shape[0]))\n",
        "    print('Validation set size: {}'.format(val_indices.shape[0]))\n",
        "    \n",
        "    x_train = x[train_indices]\n",
        "    x_val = x[val_indices]\n",
        "    y_train = y[train_indices]\n",
        "    y_val = y[val_indices]\n",
        "    \n",
        "    model = RandomForestClassifier(n_estimators=100)\n",
        "    model.fit(x_train, y_train)\n",
        "    \n",
        "    score = model.score(x_val, y_val)\n",
        "    scores_rf.append(score)\n",
        "    print('Accuracy: {}'.format(score))\n",
        "    \n",
        "print('###################################################################')\n",
        "# Evaluate estimated performance\n",
        "acc_mean = np.mean(scores_rf)\n",
        "acc_std = np.std(scores_rf)\n",
        "print('Expected accuracy: {:.2f} +- {:.2f}'.format(acc_mean, acc_std))\n",
        "\n",
        "# Evaluate actual performance\n",
        "model = RandomForestClassifier(n_estimators=100)  # Specify solver to disable warning\n",
        "model.fit(x, y)\n",
        "score = model.score(x_test, y_test)\n",
        "print('Actual accuracy:   {:.3f}'.format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t99hn-B31vdA",
        "colab_type": "text"
      },
      "source": [
        "## Compare model performance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fZ1tUES13F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(scores_lr)\n",
        "print(scores_dt)\n",
        "print(scores_rf)\n",
        "\n",
        "# Compare model averages\n",
        "acc_mean = np.mean(scores_lr)\n",
        "acc_std = np.std(scores_lr)\n",
        "print('\\nLR mean expected accuracy:: {:.2f} +- {:.2f}'.format(acc_mean, acc_std))\n",
        "acc_mean = np.mean(scores_dt)\n",
        "acc_std = np.std(scores_dt)\n",
        "print('DT mean expected accuracy:: {:.2f} +- {:.2f}'.format(acc_mean, acc_std))\n",
        "acc_mean = np.mean(scores_rf)\n",
        "acc_std = np.std(scores_rf)\n",
        "print('RF mean expected accuracy:: {:.2f} +- {:.2f}'.format(acc_mean, acc_std))\n",
        "\n",
        "# Compute t-test\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "_, p_val = ttest_ind(scores_lr, scores_dt)\n",
        "print('\\nProbability that LR has the same mean accuracy as DT: {:.4f}'.format(p_val))\n",
        "_, p_val = ttest_ind(scores_lr, scores_rf)\n",
        "print('Probability that LR has the same mean accuracy as RF: {:.4f}'.format(p_val))\n",
        "_, p_val = ttest_ind(scores_dt, scores_rf)\n",
        "print('Probability that DT has the same mean accuracy as RF: {:.4f}'.format(p_val))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}